{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def Jeval(th,X_goal):\n",
    "\n",
    "    L1 = 1\n",
    "    L2 = 1\n",
    "\n",
    "    # make th a numpy array\n",
    "    th = np.array(th)\n",
    "\n",
    "    x = L1*np.cos(th[0]) + L2*np.cos(th.sum())\n",
    "    y = L1*np.sin(th[0]) + L2*np.sin(th.sum())\n",
    "    X = np.array([[x], [y]])\n",
    "\n",
    "    diff = X - X_goal\n",
    "\n",
    "    # The cost J is equal to the distance between the end effector and the goal position\n",
    "    J = diff.T @ diff\n",
    "\n",
    "    # The gradient of J is \n",
    "    th1 = th[0]\n",
    "    th2 = th[1]\n",
    "    dxdth1 = -L1*np.sin(th1) - L2*np.sin(th1+th2)\n",
    "    dydth2 = L2*np.cos(th1) + L2*np.cos(th1+th2)\n",
    "\n",
    "    dJ0 = 2*diff[0] * dxdth1\n",
    "    dJ1 = 2*diff[1] * dydth2\n",
    "\n",
    "    J_grad = np.array([dJ0, dJ1])\n",
    "\n",
    "    return J, J_grad\n",
    "\n",
    "def grad_opt_simp(Jeval,th_init,X_goal,lr=1e-3,n_iter=1000):\n",
    "    \"\"\"\n",
    "    Simple gradient descent optimization\n",
    "    \n",
    "    Jeval: function that evaluates the cost and gradient\n",
    "\n",
    "    th_init: initial guess of the joint parameters\n",
    "    lr: learning rate\n",
    "    n_iter: number of iterations\n",
    "    \"\"\"\n",
    "    # Initialize the joint parameters\n",
    "    th0 = th_init\n",
    "\n",
    "    # Create history dictionary\n",
    "    hist = {'th0': [], 'J': []}\n",
    "\n",
    "    # Loop over iterations\n",
    "    for i in range(n_iter):\n",
    "\n",
    "        # Evaluate the cost and gradient\n",
    "        J0, J_grad0 = Jeval(th0,X_goal)\n",
    "\n",
    "        # Save the history\n",
    "        hist['th0'].append(th0)\n",
    "        hist['J'].append(J0)\n",
    "\n",
    "        # Update the joint parameters\n",
    "        th0 = th0 - lr * J_grad0\n",
    "\n",
    "    return th0, J0, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_goal:  [[1]\n",
      " [1]]\n",
      "th0:  [[0]\n",
      " [0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 32.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mX_goal: \u001b[39m\u001b[39m\"\u001b[39m, X_goal)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mth0: \u001b[39m\u001b[39m\"\u001b[39m, th0  )\n\u001b[0;32m----> 9\u001b[0m th, J, hist \u001b[39m=\u001b[39m grad_opt_simp(Jeval,th0,X_goal)\n",
      "Cell \u001b[0;32mIn[121], line 55\u001b[0m, in \u001b[0;36mgrad_opt_simp\u001b[0;34m(Jeval, th_init, X_goal, lr, n_iter)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m# Loop over iterations\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_iter):\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m     \u001b[39m# Evaluate the cost and gradient\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     J0, J_grad0 \u001b[39m=\u001b[39m Jeval(th0,X_goal)\n\u001b[1;32m     57\u001b[0m     \u001b[39m# Save the history\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     hist[\u001b[39m'\u001b[39m\u001b[39mth0\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(th0)\n",
      "Cell \u001b[0;32mIn[121], line 15\u001b[0m, in \u001b[0;36mJeval\u001b[0;34m(th, X_goal)\u001b[0m\n\u001b[1;32m     13\u001b[0m x \u001b[39m=\u001b[39m L1\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mcos(th[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m L2\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mcos(th\u001b[39m.\u001b[39msum())\n\u001b[1;32m     14\u001b[0m y \u001b[39m=\u001b[39m L1\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39msin(th[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m L2\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39msin(th\u001b[39m.\u001b[39msum())\n\u001b[0;32m---> 15\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray([[x], [y]])\n\u001b[1;32m     17\u001b[0m diff \u001b[39m=\u001b[39m X \u001b[39m-\u001b[39m X_goal\n\u001b[1;32m     19\u001b[0m \u001b[39m# The cost J is equal to the distance between the end effector and the goal position\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 32."
     ]
    }
   ],
   "source": [
    "th1 = 0\n",
    "th2 = 0\n",
    "th0 = np.array([[th1], [th2]])\n",
    "X_goal = np.array([[1], [1]])\n",
    "\n",
    "print(\"X_goal: \", X_goal)\n",
    "print(\"th0: \", th0  )\n",
    "\n",
    "th, J, hist = grad_opt_simp(Jeval,th0,X_goal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2R_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
